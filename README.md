# Disaster-Response-Pipeline

## Project Overview

This initiative is part of the Data Science Nanodegree Program offered by Udacity in partnership with Figure Eight. The project involves leveraging a dataset of pre-categorized tweets and messages related to actual disaster events. The goal is to develop a Natural Language Processing (NLP) model capable of categorizing messages in real time.

The project is structured into three main phases:

1- Data Processing: Create an ETL (Extract, Transform, Load) pipeline to retrieve data from its original source, perform data cleaning, and store the processed data in a SQLite database.

2- Machine Learning Model Development: Construct a machine learning pipeline to train a model that can classify text messages into various categories.

3- Web Application: Develop a web application that displays real-time results from the trained model.

Certainly! Here’s a revised version of the “Getting Started” section:


## Getting Started

Requirements:

- Python: Version 3.5 or higher
- Machine Learning Libraries: NumPy, SciPy, Pandas, Scikit-Learn
- Natural Language Processing Libraries: NLTK
- SQLite Database Libraries: SQLalchemy
- Model Serialization: Pickle
- Web Application and Data Visualization: Flask, Plotly


## Installing 

To copy the Git repository:

https://github.com/2140785/Disaster-Response-Pipeline

## Screenshots

1- Sample run of process_data.py
<img width="468" alt="image" src="https://github.com/user-attachments/assets/fdc54d48-ecb9-473e-bcb0-c0f38d504b23">

2- Sample run of train_classifier.py
<img width="468" alt="image" src="https://github.com/user-attachments/assets/0521f4e4-c21e-4af4-8c4e-e521b0e134da">

